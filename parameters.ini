[mode]
pretrained_word_embedding = True 
word_embedding_path = ../../word_embedding/word_embedding.txt
pos_word_embedding_path = ../../word_embedding/pos_word_embedding.txt
feature_extract_mode = cnn
word_type =

[dataset]
dataset_text_folder = ../../data/Bigram_Data
#dataset_text_folder = ../../data/Pos_Data
#dataset_text_folder = ../../data/Token_Data

[ann]
jaso_embedding_dim = 25
char_embedding_dim = 25
word_embedding_dim = 50
pos_word_embedding_dim = 64

filter_size = 2
num_filters = 30
word_filter_size = 2,3
word_num_filters = 100
l2_reg_lambda = 0.001

char_lstm_hidden_state_dim = 30
lstm_hidden_state_dim = 100

[training]
patience = 10
maximum_number_of_epochs = 100
evaluation_every = 1000
checkpoint_every = 1000
batch_size = 32

# dropout_rate should be between 0 and 1
dropout_rate = 0.5

# Upper bound on the number of CPU threads
number_of_cpu_threads = 8
